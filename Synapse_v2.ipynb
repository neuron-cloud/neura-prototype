{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "1eaHX1ztkfp0",
        "outputId": "4f4d76b0-8f36-4b27-d1e2-7302260edff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§  Synapse v2.0 loaded successfully!\n",
            "\n",
            "============================================================\n",
            "USAGE:\n",
            "Just paste your clinical text below and press Enter:\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-bdf52115414a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;31m# Direct input in Jupyter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m         \u001b[0mclinical_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ðŸ“‹ Clinical Note: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclinical_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import time\n",
        "import traceback\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "from dataclasses import dataclass, field\n",
        "from enum import Enum\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# === Configuration Management ===\n",
        "class Config:\n",
        "    \"\"\"Configuration management for Synapse\"\"\"\n",
        "    def __init__(self):\n",
        "        # Set your actual OpenAI API key here or use environment variable\n",
        "        self.openai_api_key = os.getenv('OPENAI_API_KEY', 'Inset Your Open API Key Here')\n",
        "        self.log_level = os.getenv('LOG_LEVEL', 'WARNING')  # Less verbose by default\n",
        "        self.enable_gpt_summary = os.getenv('ENABLE_GPT_SUMMARY', 'true').lower() == 'true'\n",
        "        self.confidence_threshold = float(os.getenv('CONFIDENCE_THRESHOLD', '0.7'))\n",
        "        self.enable_stroke_detection = os.getenv('ENABLE_STROKE_DETECTION', 'true').lower() == 'true'\n",
        "        self.enable_seizure_detection = os.getenv('ENABLE_SEIZURE_DETECTION', 'true').lower() == 'true'\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# === Severity Levels ===\n",
        "class Severity(Enum):\n",
        "    CRITICAL = \"ðŸš¨\"\n",
        "    WARNING = \"âš ï¸\"\n",
        "    MOTOR = \"ðŸ¦´\"\n",
        "    NEURO = \"ðŸ§ \"\n",
        "    MONITORING = \"ðŸ”\"\n",
        "    NORMAL = \"âœ…\"\n",
        "\n",
        "# === Structured Clinical Findings ===\n",
        "@dataclass\n",
        "class ClinicalFinding:\n",
        "    \"\"\"Structured representation of a clinical finding\"\"\"\n",
        "    message: str\n",
        "    severity: Severity\n",
        "    confidence: float\n",
        "    category: str\n",
        "    negated: bool = False\n",
        "    baseline: bool = False\n",
        "    timestamp: datetime = field(default_factory=datetime.now)\n",
        "\n",
        "@dataclass\n",
        "class ClinicalFindings:\n",
        "    \"\"\"Collection of all clinical findings\"\"\"\n",
        "    critical_flags: List[ClinicalFinding] = field(default_factory=list)\n",
        "    warning_flags: List[ClinicalFinding] = field(default_factory=list)\n",
        "    motor_flags: List[ClinicalFinding] = field(default_factory=list)\n",
        "    neuro_flags: List[ClinicalFinding] = field(default_factory=list)\n",
        "    monitoring_flags: List[ClinicalFinding] = field(default_factory=list)\n",
        "    normal_findings: List[ClinicalFinding] = field(default_factory=list)\n",
        "    overall_confidence: float = 0.0\n",
        "    processing_time_ms: int = 0\n",
        "\n",
        "    def get_all_findings(self) -> List[ClinicalFinding]:\n",
        "        \"\"\"Get all findings sorted by severity\"\"\"\n",
        "        all_findings = (self.critical_flags + self.warning_flags +\n",
        "                       self.motor_flags + self.neuro_flags +\n",
        "                       self.monitoring_flags + self.normal_findings)\n",
        "        return sorted(all_findings, key=lambda x: list(Severity).index(x.severity))\n",
        "\n",
        "# === Compiled Patterns for Performance ===\n",
        "class CompiledPatterns:\n",
        "    \"\"\"Pre-compiled regex patterns for better performance\"\"\"\n",
        "    def __init__(self):\n",
        "        # Consciousness patterns\n",
        "        self.gcs_pattern = re.compile(r'gcs\\s*(?:of|is|at|score)?\\s*(\\d+)', re.IGNORECASE)\n",
        "        self.gcs15_pattern = re.compile(r'gcs\\s*(?:of|is|at|score)?\\s*15|glasgow\\s+(?:coma\\s+)?(?:scale|score)\\s*(?:of|is|at)?\\s*15', re.IGNORECASE)\n",
        "\n",
        "        # Motor strength patterns - Enhanced for both abbreviated and expanded forms\n",
        "        self.detailed_strength_pattern = re.compile(r'(rue|lue|rle|lle|right\\s+upper\\s+extremity|left\\s+upper\\s+extremity|right\\s+lower\\s+extremity|left\\s+lower\\s+extremity)\\s+(\\d+[-+]?/\\d+[-+]?/\\d+[-+]?/\\d+[-+]?/\\d+[-+]?)', re.IGNORECASE)\n",
        "        self.generalized_strength_pattern = re.compile(r'(rue|lue|rle|lle|right\\s+upper\\s+extremity|left\\s+upper\\s+extremity|right\\s+lower\\s+extremity|left\\s+lower\\s+extremity)\\s+(\\d+[-+]?)\\s+throughout', re.IGNORECASE)\n",
        "\n",
        "        # Sensory level pattern - more flexible\n",
        "        self.sensory_level_pattern = re.compile(r'~?([tl]\\d+)\\s+sensory\\s+level', re.IGNORECASE)\n",
        "\n",
        "        # Clonus pattern - more flexible\n",
        "        self.clonus_pattern = re.compile(r'(rt|lt|right|left|r|l)?\\s*clonus', re.IGNORECASE)\n",
        "\n",
        "        # Babinski pattern\n",
        "        self.babinski_pattern = re.compile(r'(rt|lt|right|left|r|l)?\\s*babinski', re.IGNORECASE)\n",
        "\n",
        "        # Hyperreflexia patterns\n",
        "        self.hyperreflexia_pattern = re.compile(r'(rue|lue|rle|lle|right|left|bilateral|bl)?\\s*(?:dtrs?|reflexes?)\\s*(\\d+\\+)', re.IGNORECASE)\n",
        "\n",
        "        # Saddle anesthesia pattern\n",
        "        self.saddle_anesthesia_pattern = re.compile(r'saddle\\s+anesthesia', re.IGNORECASE)\n",
        "\n",
        "        # Sensory deficit patterns\n",
        "        self.sensory_deficit_pattern = re.compile(r'(?:decreased|diminished|reduced|impaired|absent)\\s+sensation', re.IGNORECASE)\n",
        "        self.bilateral_sensory_pattern = re.compile(r'(?:bilateral|bl|both)\\s+(?:feet|soles|lower\\s+extremit)', re.IGNORECASE)\n",
        "\n",
        "        # Reflex patterns\n",
        "        self.absent_reflexes_pattern = re.compile(r'absent\\s+(?:patellar|knee|dtr|reflex)', re.IGNORECASE)\n",
        "        self.hyporeflexia_pattern = re.compile(r'(?:hyporeflexia|areflexia|absent.*reflex)', re.IGNORECASE)\n",
        "\n",
        "        # Spinal tumor patterns\n",
        "        self.spinal_tumor_pattern = re.compile(r'(?:plasmacytoma|myeloma|metastas|tumor).*(?:spine|spinal|vertebr)', re.IGNORECASE)\n",
        "\n",
        "# Global compiled patterns instance\n",
        "patterns = CompiledPatterns()\n",
        "\n",
        "# === Enhanced Abbreviation Dictionary ===\n",
        "abbreviation_map = {\n",
        "    # Common medical prefixes\n",
        "    \"pmh\": \"past medical history\",\n",
        "    \"hx\": \"history\",\n",
        "    \"s/p\": \"status post\",\n",
        "    \"p/t\": \"presenting to\",\n",
        "    \"p/w\": \"presented with\",\n",
        "    \"c/f\": \"concern for\",\n",
        "    \"c/b\": \"complicated by\",\n",
        "    \"c/t\": \"compared to\",\n",
        "    \"c/s\": \"consult\",\n",
        "    \"w/\": \"with\",\n",
        "    \"w/o\": \"without\",\n",
        "    \"wo\": \"without\",\n",
        "    \"wwo\": \"with and without\",\n",
        "    \"b/b\": \"bowel or bladder\",\n",
        "    \"2/2\": \"secondary to\",\n",
        "\n",
        "    # Locations and facilities\n",
        "    \"ED\": \"emergency department\",\n",
        "    \"OSH\": \"outside hospital\",\n",
        "    \"CCH\": \"Cook County Hospital\",\n",
        "    \"NSGY\": \"neurosurgery\",\n",
        "\n",
        "    # Imaging\n",
        "    \"CTA\": \"computed tomography angiography\",\n",
        "    \"CTH\": \"CT head\",\n",
        "    \"CAP\": \"chest abdomen pelvis\",\n",
        "    \"MRI\": \"magnetic resonance imaging\",\n",
        "    \"XR\": \"x-ray\",\n",
        "\n",
        "    # Procedures\n",
        "    \"ACDF\": \"anterior cervical discectomy and fusion\",\n",
        "    \"lami\": \"laminectomy\",\n",
        "    \"lamis\": \"laminectomies\",\n",
        "\n",
        "    # Conditions\n",
        "    \"tSAH\": \"traumatic subarachnoid hemorrhage\",\n",
        "    \"SDH\": \"subdural hematoma\",\n",
        "    \"aSDH\": \"acute subdural hematoma\",\n",
        "    \"mets\": \"metastases\",\n",
        "    \"AMS\": \"altered mental status\",\n",
        "    \"AVN\": \"avascular necrosis\",\n",
        "    \"fx\": \"fracture\",\n",
        "    \"comp fx\": \"compression fracture\",\n",
        "\n",
        "    # Body parts and directions\n",
        "    \"TP\": \"transverse process\",\n",
        "    \"SP\": \"spinous process\",\n",
        "    \"BL\": \"bilateral\",\n",
        "    \"Rt\": \"right\",\n",
        "    \"Lt\": \"left\",\n",
        "    \"L\": \"left\",\n",
        "    \"R\": \"right\",\n",
        "    \"RUE\": \"right upper extremity\",\n",
        "    \"LUE\": \"left upper extremity\",\n",
        "    \"RLE\": \"right lower extremity\",\n",
        "    \"LLE\": \"left lower extremity\",\n",
        "    \"BUE\": \"bilateral upper extremities\",\n",
        "    \"BLE\": \"bilateral lower extremities\",\n",
        "    \"RUL\": \"right upper lobe\",\n",
        "    \"LBP\": \"low back pain\",\n",
        "\n",
        "    # Examination terms\n",
        "    \"DTR\": \"deep tendon reflex\",\n",
        "    \"DTRs\": \"deep tendon reflexes\",\n",
        "    \"TTP\": \"tenderness to palpation\",\n",
        "    \"MAES\": \"moves all extremities spontaneously\",\n",
        "    \"maes\": \"moves all extremities spontaneously\",\n",
        "    \"EHL\": \"extensor hallucis longus\",\n",
        "\n",
        "    # Orientation\n",
        "    \"ox0\": \"not oriented to person, place, or time\",\n",
        "    \"ox1\": \"oriented to person only\",\n",
        "    \"ox2\": \"oriented to person and place or time\",\n",
        "    \"ox3\": \"oriented to person, place, and time\",\n",
        "    \"GCS\": \"Glasgow Coma Scale\",\n",
        "\n",
        "    # Movement responses\n",
        "    \"loc\": \"localizes to pain\",\n",
        "    \"wd\": \"withdraws to pain\",\n",
        "\n",
        "    # Trauma\n",
        "    \"GLF\": \"ground level fall\",\n",
        "    \"LOC\": \"loss of consciousness\",\n",
        "    \"BHT\": \"blunt head trauma\",\n",
        "    \"MVC\": \"motor vehicle collision\",\n",
        "    \"MVA\": \"motor vehicle accident\",\n",
        "\n",
        "    # Patient state\n",
        "    \"ADLs\": \"activities of daily living\",\n",
        "    \"ACAP\": \"anticoagulant or antiplatelet therapy\",\n",
        "    \"PVR\": \"post-void residual\",\n",
        "\n",
        "    # Anatomical regions\n",
        "    \"T-spine\": \"thoracic spine\",\n",
        "    \"L-spine\": \"lumbar spine\",\n",
        "    \"C-spine\": \"cervical spine\",\n",
        "\n",
        "    # Time descriptors\n",
        "    \"dx\": \"diagnosed\",\n",
        "    \"x3d\": \"for 3 days\",\n",
        "    \"x2d\": \"for 2 days\",\n",
        "    \"x4d\": \"for 4 days\",\n",
        "    \"x10d\": \"for 10 days\",\n",
        "    \"x1w\": \"for 1 week\",\n",
        "    \"x1mo\": \"for 1 month\",\n",
        "\n",
        "    # Labs\n",
        "    \"Na\": \"sodium\",\n",
        "    \"CBC\": \"complete blood count\",\n",
        "    \"BMP\": \"basic metabolic panel\",\n",
        "    \"Coags\": \"coagulation studies\",\n",
        "    \"HH\": \"hemoglobin hematocrit\",\n",
        "    \"PLT\": \"platelets\",\n",
        "    \"PT\": \"prothrombin time\",\n",
        "    \"INR\": \"international normalized ratio\",\n",
        "    \"EtOH\": \"alcohol\",\n",
        "\n",
        "    # Status descriptors\n",
        "    \"neg\": \"negative\",\n",
        "    \"nl\": \"normal\",\n",
        "    \"wnl\": \"within normal limits\",\n",
        "    \"N/V\": \"nausea and vomiting\",\n",
        "    \"HA\": \"headache\",\n",
        "    \"Pt\": \"patient\",\n",
        "    \"pt\": \"patient\",\n",
        "    \"s/s\": \"signs and symptoms\",\n",
        "    \"AFO\": \"ankle-foot orthosis\",\n",
        "    \"â†“\": \"decreased\",\n",
        "    \"â†‘\": \"increased\",\n",
        "\n",
        "    # Comorbidities\n",
        "    \"HTN\": \"hypertension\",\n",
        "    \"HLD\": \"hyperlipidemia\",\n",
        "    \"HF\": \"heart failure\",\n",
        "    \"PE\": \"pulmonary embolism\",\n",
        "    \"DVT\": \"deep vein thrombosis\",\n",
        "    \"Ca\": \"cancer\",\n",
        "\n",
        "    # Treatments\n",
        "    \"PT\": \"physical therapy\",\n",
        "    \"Tx\": \"treatment\",\n",
        "    \"ASA\": \"aspirin\",\n",
        "    \"tx\": \"treatment\"\n",
        "}\n",
        "\n",
        "# === Enhanced Logging System ===\n",
        "class ClinicalLogger:\n",
        "    \"\"\"Enhanced logging system for clinical processing\"\"\"\n",
        "    def __init__(self):\n",
        "        self.logger = logging.getLogger('synapse')\n",
        "        self.logger.setLevel(getattr(logging, config.log_level))\n",
        "\n",
        "        # Create console handler\n",
        "        handler = logging.StreamHandler()\n",
        "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "        handler.setFormatter(formatter)\n",
        "        self.logger.addHandler(handler)\n",
        "\n",
        "        # Audit trail\n",
        "        self.audit_trail = []\n",
        "\n",
        "    def log_clinical_processing(self, input_text: str, findings: ClinicalFindings,\n",
        "                              abbreviations_expanded: List[str]):\n",
        "        \"\"\"Log clinical processing details\"\"\"\n",
        "        audit_entry = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'input_length': len(input_text),\n",
        "            'abbreviations_expanded': abbreviations_expanded,\n",
        "            'findings_count': len(findings.get_all_findings()),\n",
        "            'processing_time_ms': findings.processing_time_ms,\n",
        "            'confidence': findings.overall_confidence\n",
        "        }\n",
        "        self.audit_trail.append(audit_entry)\n",
        "\n",
        "        self.logger.info(f\"Processed clinical text: {len(findings.get_all_findings())} findings, \"\n",
        "                        f\"{findings.processing_time_ms}ms, confidence: {findings.overall_confidence:.2f}\")\n",
        "\n",
        "    def log_error(self, component: str, error_code: str, error_message: str,\n",
        "                  severity: str = \"medium\", stack_trace: str = None):\n",
        "        \"\"\"Log errors with structured format\"\"\"\n",
        "        error_entry = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'component': component,\n",
        "            'error_code': error_code,\n",
        "            'error_message': error_message,\n",
        "            'severity': severity,\n",
        "            'stack_trace': stack_trace\n",
        "        }\n",
        "        self.audit_trail.append(error_entry)\n",
        "\n",
        "        self.logger.error(f\"[{component}] {error_code}: {error_message}\")\n",
        "        if stack_trace:\n",
        "            self.logger.debug(stack_trace)\n",
        "\n",
        "# Global logger instance\n",
        "clinical_logger = ClinicalLogger()\n",
        "\n",
        "# === Enhanced Abbreviation Expansion ===\n",
        "def expand_abbreviations(blurb: str, dictionary: Dict[str, str]) -> Tuple[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Improved abbreviation expansion with context awareness and performance optimization\n",
        "    \"\"\"\n",
        "    if not blurb:\n",
        "        return blurb, []\n",
        "\n",
        "    expanded_terms = set()\n",
        "    blurb_original = blurb\n",
        "\n",
        "    try:\n",
        "        # First pass: complete word matches (with boundaries)\n",
        "        for abbr, full in dictionary.items():\n",
        "            # Skip very short abbreviations that might cause issues\n",
        "            if len(abbr) <= 1:\n",
        "                continue\n",
        "\n",
        "            # Use word boundaries for complete word matches\n",
        "            pattern = r'\\b' + re.escape(abbr) + r'\\b'\n",
        "            matches = re.findall(pattern, blurb, re.IGNORECASE)\n",
        "\n",
        "            if matches:\n",
        "                expanded_terms.add(abbr)\n",
        "                blurb = re.sub(pattern, full, blurb, flags=re.IGNORECASE)\n",
        "\n",
        "        # Second pass: special patterns without boundaries\n",
        "        special_patterns = {\n",
        "            r's/p': 'status post',\n",
        "            r'c/f': 'concern for',\n",
        "            r'p/t': 'presenting to',\n",
        "            r'c/t': 'compared to',\n",
        "            r'c/b': 'complicated by',\n",
        "            r'c/s': 'consult',\n",
        "            r'w/': 'with',\n",
        "            r'w/o': 'without',\n",
        "            r'b/b': 'bowel or bladder',\n",
        "            r'2/2': 'secondary to',\n",
        "            r'p/w': 'presented with'\n",
        "        }\n",
        "\n",
        "        for pattern, replacement in special_patterns.items():\n",
        "            matches = re.findall(re.escape(pattern), blurb, re.IGNORECASE)\n",
        "            if matches:\n",
        "                expanded_terms.add(pattern)\n",
        "                blurb = re.sub(re.escape(pattern), replacement, blurb, flags=re.IGNORECASE)\n",
        "\n",
        "        clinical_logger.logger.debug(f\"Expanded {len(expanded_terms)} abbreviations: {', '.join(expanded_terms)}\")\n",
        "        return blurb, list(expanded_terms)\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error in abbreviation expansion: {str(e)}\"\n",
        "        clinical_logger.log_error(\n",
        "            component=\"abbreviation_expansion\",\n",
        "            error_code=\"EXPANSION_ERROR\",\n",
        "            error_message=error_msg,\n",
        "            stack_trace=traceback.format_exc()\n",
        "        )\n",
        "        return blurb_original, []\n",
        "\n",
        "# === Enhanced Negation Detection ===\n",
        "def is_negated(term: str, blurb: str) -> bool:\n",
        "    \"\"\"\n",
        "    Enhanced negation detection with improved context awareness\n",
        "    \"\"\"\n",
        "    if not term or not blurb:\n",
        "        return False\n",
        "\n",
        "    term = term.strip().lower()\n",
        "    blurb_lower = blurb.lower()\n",
        "\n",
        "    # Special handling for exam findings - if something appears after \"exam:\" or \"intact except\", it's usually a positive finding\n",
        "    exam_sections = re.split(r'exam\\s*:', blurb_lower)\n",
        "    if len(exam_sections) > 1:\n",
        "        exam_part = exam_sections[-1]  # Get the part after \"exam:\"\n",
        "        if term in exam_part:\n",
        "            # Check if it's in an \"intact except\" context - these are positive findings\n",
        "            if re.search(r'intact\\s+except.*?' + re.escape(term), exam_part):\n",
        "                return False\n",
        "            # Check if it's directly after exam findings without negation\n",
        "            if not re.search(r'(?:denies|no|negative|without|absent)\\s+.*?' + re.escape(term), exam_part):\n",
        "                return False\n",
        "\n",
        "    # Parse the text into sentences to restrict negation scope\n",
        "    sentences = re.split(r'[.!?]\\s+', blurb_lower)\n",
        "\n",
        "    # Check sentences containing the term\n",
        "    for sentence in sentences:\n",
        "        if term in sentence:\n",
        "            # If the sentence contains \"intact except\", findings after that are positive\n",
        "            if 'intact except' in sentence:\n",
        "                intact_except_pos = sentence.find('intact except')\n",
        "                term_pos = sentence.find(term)\n",
        "                if term_pos > intact_except_pos:\n",
        "                    return False  # Term appears after \"intact except\" so it's a positive finding\n",
        "\n",
        "            # Check for denial patterns in the sentence\n",
        "            denial_patterns = [\n",
        "                r'denies', r'denied', r'no', r'not', r'negative',\n",
        "                r'absence of', r'without', r'hasn\\'t', r'doesn\\'t',\n",
        "                r'has not', r'does not', r'not (?:having|experiencing|showing)',\n",
        "                r'hasn\\'t endorsed', r'hasn\\'t had', r'hasn\\'t experienced'\n",
        "            ]\n",
        "\n",
        "            # Only consider negation if the denial word is close to the term (within 10 words)\n",
        "            for pattern in denial_patterns:\n",
        "                denial_matches = list(re.finditer(pattern, sentence))\n",
        "                for denial_match in denial_matches:\n",
        "                    denial_pos = denial_match.end()\n",
        "                    term_pos = sentence.find(term)\n",
        "                    if term_pos > denial_pos:\n",
        "                        # Check if there are too many words between denial and term\n",
        "                        words_between = len(sentence[denial_pos:term_pos].split())\n",
        "                        if words_between <= 10:  # Only negate if close proximity\n",
        "                            # Check for double negatives\n",
        "                            if not re.search(r'not.+?(?:denied|negative|absent)', sentence):\n",
        "                                return True\n",
        "\n",
        "    return False\n",
        "\n",
        "# === Enhanced Exam Components Extraction ===\n",
        "def extract_enhanced_exam_components(blurb: str, blurb_lower: str) -> List[ClinicalFinding]:\n",
        "    \"\"\"\n",
        "    Comprehensive exam component extraction with all clinical patterns\n",
        "    \"\"\"\n",
        "    findings = []\n",
        "\n",
        "    try:\n",
        "        # Identify exam section\n",
        "        exam_section = blurb_lower\n",
        "        exam_section_patterns = [\n",
        "            r'exam(?:\\s*[-:]\\s*)(.*?)(?:\\n\\n|\\Z)',\n",
        "            r'(?:physical|neuro(?:logical)?|motor)\\s+exam(?:\\s*[-:]\\s*)(.*?)(?:\\n\\n|\\Z)',\n",
        "            r'(?:physical|neurological) findings(?:\\s*[-:]\\s*)(.*?)(?:\\n\\n|\\Z)'\n",
        "        ]\n",
        "\n",
        "        for pattern in exam_section_patterns:\n",
        "            match = re.search(pattern, blurb_lower, re.DOTALL)\n",
        "            if match:\n",
        "                exam_section = match.group(1).strip()\n",
        "                break\n",
        "\n",
        "        # === CONSCIOUSNESS AND ORIENTATION ASSESSMENT ===\n",
        "        # Check for GCS score\n",
        "        gcs_pattern = r'gcs\\s*(?:of|is|at|score)?\\s*(\\d+)'\n",
        "        gcs_match = re.search(gcs_pattern, exam_section)\n",
        "\n",
        "        if gcs_match:\n",
        "            gcs_score = int(gcs_match.group(1))\n",
        "            if gcs_score == 15:\n",
        "                findings.append(ClinicalFinding(\n",
        "                    message=\"Full consciousness: GCS 15\",\n",
        "                    severity=Severity.NORMAL,\n",
        "                    confidence=0.95,\n",
        "                    category=\"consciousness\"\n",
        "                ))\n",
        "            elif gcs_score >= 13:\n",
        "                findings.append(ClinicalFinding(\n",
        "                    message=f\"Mild consciousness impairment: GCS {gcs_score}\",\n",
        "                    severity=Severity.MONITORING,\n",
        "                    confidence=0.9,\n",
        "                    category=\"consciousness\"\n",
        "                ))\n",
        "            elif gcs_score >= 9:\n",
        "                findings.append(ClinicalFinding(\n",
        "                    message=f\"Moderate consciousness impairment: GCS {gcs_score}\",\n",
        "                    severity=Severity.WARNING,\n",
        "                    confidence=0.95,\n",
        "                    category=\"consciousness\"\n",
        "                ))\n",
        "            else:\n",
        "                findings.append(ClinicalFinding(\n",
        "                    message=f\"Severe consciousness impairment: GCS {gcs_score}\",\n",
        "                    severity=Severity.CRITICAL,\n",
        "                    confidence=0.98,\n",
        "                    category=\"consciousness\"\n",
        "                ))\n",
        "\n",
        "        # Check for arousal descriptions\n",
        "        arousal_patterns = {\n",
        "            r'(?:eyes?\\s+open(?:ing)?)\\s+(?:to|with)\\s+(?:heavy\\s+)?(?:stim|stimulation|pain)': (\n",
        "                \"Decreased arousal levelâ€”requires stimulation for eye opening\", Severity.NEURO, 0.85),\n",
        "            r'alert|awake|wide awake': (\n",
        "                \"Alert and awake\", Severity.NORMAL, 0.9),\n",
        "            r'drowsy|lethargic|somnolent': (\n",
        "                \"Decreased arousalâ€”drowsy/lethargic\", Severity.NEURO, 0.8)\n",
        "        }\n",
        "\n",
        "        for pattern, (message, severity, confidence) in arousal_patterns.items():\n",
        "            match = re.search(pattern, exam_section)\n",
        "            if match and not is_negated(match.group(0), blurb_lower):\n",
        "                findings.append(ClinicalFinding(\n",
        "                    message=message,\n",
        "                    severity=severity,\n",
        "                    confidence=confidence,\n",
        "                    category=\"arousal\"\n",
        "                ))\n",
        "\n",
        "        # Check for orientation status\n",
        "        orientation_patterns = {\n",
        "            r'\\box0\\b|not oriented|disoriented': (\n",
        "                \"Altered mental status: Ox0 or disoriented\", Severity.NEURO, 0.9),\n",
        "            r'\\box1\\b|oriented to person only': (\n",
        "                \"Partial orientation: Ox1\", Severity.NEURO, 0.85),\n",
        "            r'\\box2\\b|oriented to person and (place|time)': (\n",
        "                \"Oriented to person and place: Ox2\", Severity.MONITORING, 0.8),\n",
        "            r'\\box3\\b|oriented x3|fully oriented': (\n",
        "                \"Fully oriented: Ox3\", Severity.NORMAL, 0.9)\n",
        "        }\n",
        "\n",
        "        for pattern, (message, severity, confidence) in orientation_patterns.items():\n",
        "            match = re.search(pattern, exam_section)\n",
        "            if match and not is_negated(match.group(0), blurb_lower):\n",
        "                findings.append(ClinicalFinding(\n",
        "                    message=message,\n",
        "                    severity=severity,\n",
        "                    confidence=confidence,\n",
        "                    category=\"orientation\"\n",
        "                ))\n",
        "                break  # Only add the most specific orientation finding\n",
        "\n",
        "        # === MOTOR RESPONSES TO PAINFUL STIMULI ===\n",
        "        motor_response_patterns = {\n",
        "            r'bue\\s+loc': (\n",
        "                \"Localizes to pain in bilateral upper extremities\", Severity.NEURO, 0.85),\n",
        "            r'ble\\s+wd': (\n",
        "                \"Withdrawal response in bilateral lower extremities\", Severity.NEURO, 0.85),\n",
        "            r'bue\\s+loc\\s+ble\\s+wd': (\n",
        "                \"Localizes in upper extremities, withdraws in lower extremities\", Severity.NEURO, 0.9),\n",
        "            r'(?:does not follow|unable to follow) commands': (\n",
        "                \"Decreased level of consciousnessâ€”unable to follow commands\", Severity.NEURO, 0.9),\n",
        "            r'follows? commands': (\n",
        "                \"Follows commands appropriately\", Severity.NORMAL, 0.85)\n",
        "        }\n",
        "\n",
        "        for pattern, (message, severity, confidence) in motor_response_patterns.items():\n",
        "            match = re.search(pattern, exam_section)\n",
        "            if match and not is_negated(match.group(0), blurb_lower):\n",
        "                findings.append(ClinicalFinding(\n",
        "                    message=message,\n",
        "                    severity=severity,\n",
        "                    confidence=confidence,\n",
        "                    category=\"motor_response\"\n",
        "                ))\n",
        "\n",
        "        # === CRANIAL NERVE EXAMINATION ===\n",
        "        cranial_nerve_patterns = {\n",
        "            r'(?:facial|face)\\s+(?:droop|weakness|asymmetry)': (\n",
        "                \"Facial droopâ€”possible cranial nerve VII weakness\", Severity.MOTOR, 0.85),\n",
        "            r'(?:tongue|lingual)\\s+(?:deviation|weakness)': (\n",
        "                \"Tongue deviationâ€”possible cranial nerve XII weakness\", Severity.MOTOR, 0.85),\n",
        "            r'(?:slurred|dysarthric)\\s+speech': (\n",
        "                \"Dysarthria/slurred speechâ€”monitor for progression\", Severity.NEURO, 0.8)\n",
        "        }\n",
        "\n",
        "        for pattern, (message, severity, confidence) in cranial_nerve_patterns.items():\n",
        "            match = re.search(pattern, exam_section)\n",
        "            if match and not is_negated(match.group(0), blurb_lower):\n",
        "                findings.append(ClinicalFinding(\n",
        "                    message=message,\n",
        "                    severity=severity,\n",
        "                    confidence=confidence,\n",
        "                    category=\"cranial_nerves\"\n",
        "                ))\n",
        "\n",
        "        # === COMPREHENSIVE MOTOR STRENGTH ASSESSMENT ===\n",
        "        limb_map = {\n",
        "            \"rue\": \"RIGHT UPPER EXTREMITY\",\n",
        "            \"lue\": \"LEFT UPPER EXTREMITY\",\n",
        "            \"rle\": \"RIGHT LOWER EXTREMITY\",\n",
        "            \"lle\": \"LEFT LOWER EXTREMITY\",\n",
        "            \"bue\": \"BILATERAL UPPER EXTREMITIES\",\n",
        "            \"ble\": \"BILATERAL LOWER EXTREMITIES\",\n",
        "            \"right arm\": \"RIGHT UPPER EXTREMITY\",\n",
        "            \"left arm\": \"LEFT UPPER EXTREMITY\",\n",
        "            \"right upper extremity\": \"RIGHT UPPER EXTREMITY\",\n",
        "            \"left upper extremity\": \"LEFT UPPER EXTREMITY\",\n",
        "            \"right leg\": \"RIGHT LOWER EXTREMITY\",\n",
        "            \"left leg\": \"LEFT LOWER EXTREMITY\",\n",
        "            \"right lower extremity\": \"RIGHT LOWER EXTREMITY\",\n",
        "            \"left lower extremity\": \"LEFT LOWER EXTREMITY\"\n",
        "        }\n",
        "\n",
        "        muscle_groups = {\n",
        "            \"RIGHT UPPER EXTREMITY\": [\"shoulder abduction\", \"elbow flexion\", \"elbow extension\", \"wrist extension\", \"handgrip\"],\n",
        "            \"LEFT UPPER EXTREMITY\": [\"shoulder abduction\", \"elbow flexion\", \"elbow extension\", \"wrist extension\", \"handgrip\"],\n",
        "            \"RIGHT LOWER EXTREMITY\": [\"hip flexion\", \"knee extension\", \"ankle dorsiflexion\", \"EHL\", \"ankle plantarflexion\"],\n",
        "            \"LEFT LOWER EXTREMITY\": [\"hip flexion\", \"knee extension\", \"ankle dorsiflexion\", \"EHL\", \"ankle plantarflexion\"]\n",
        "        }\n",
        "\n",
        "        processed_extremities = set()\n",
        "        exam_normalized = exam_section\n",
        "\n",
        "        # Normalize strength notation\n",
        "        exam_normalized = re.sub(r'(\\d+[-+]?)\\s+(\\d+[-+]?)', r'\\1/\\2', exam_normalized)\n",
        "        exam_normalized = re.sub(r'(\\d+[-+]?)[,;](\\d+[-+]?)', r'\\1/\\2', exam_normalized)\n",
        "        exam_normalized = re.sub(r'(\\d+)s', r'\\1', exam_normalized)\n",
        "\n",
        "        # Complex multiple muscle strength (e.g., RUE 5/5/5/4-/4)\n",
        "        complex_pattern = r'(rue|lue|rle|lle|right\\s+upper\\s+extremity|left\\s+upper\\s+extremity|right\\s+lower\\s+extremity|left\\s+lower\\s+extremity)(?:\\s*[:;-])?\\s*(?:\\()?(\\d+[-+]?(?:[\\/\\s,.-]?\\d+[-+]?){2,4})(?:\\))?'\n",
        "        complex_matches = re.finditer(complex_pattern, exam_normalized, re.IGNORECASE)\n",
        "\n",
        "        for match in complex_matches:\n",
        "            extremity = match.group(1).lower().replace(' ', ' ')\n",
        "            if extremity in processed_extremities:\n",
        "                continue\n",
        "\n",
        "            extremity_name = limb_map.get(extremity, extremity.upper())\n",
        "            strength_text = match.group(2)\n",
        "            values = re.findall(r'(\\d+[-+]?)', strength_text)\n",
        "\n",
        "            weak_values = []\n",
        "            for i, val in enumerate(values):\n",
        "                if val.strip() not in ['5', '5+']:\n",
        "                    if extremity_name in muscle_groups and i < len(muscle_groups[extremity_name]):\n",
        "                        muscle_name = muscle_groups[extremity_name][i]\n",
        "                    else:\n",
        "                        muscle_name = f\"muscle {i+1}\"\n",
        "                    weak_values.append(f\"{muscle_name}: {val}\")\n",
        "\n",
        "            if weak_values:\n",
        "                processed_extremities.add(extremity)\n",
        "                weakness_details = \", \".join(weak_values)\n",
        "\n",
        "                # Check severity\n",
        "                has_severe_weakness = any(int(val.strip().replace('+', '').replace('-', '')) <= 2\n",
        "                                        for val in values if val.strip().replace('+', '').replace('-', '').isdigit())\n",
        "                severity = Severity.WARNING if has_severe_weakness else Severity.MOTOR\n",
        "                confidence = 0.95 if has_severe_weakness else 0.85\n",
        "\n",
        "                findings.append(ClinicalFinding(\n",
        "                    message=f\"Weakness in {extremity_name}: {weakness_details}\",\n",
        "                    severity=severity,\n",
        "                    confidence=confidence,\n",
        "                    category=\"motor\"\n",
        "                ))\n",
        "\n",
        "        # Simple strength scores (e.g., LUE 4+/5)\n",
        "        simple_pattern = r'(rue|lue|rle|lle|right arm|left arm|right leg|left leg)\\s+(\\d+[-+]?)/5'\n",
        "        simple_matches = re.finditer(simple_pattern, exam_section, re.IGNORECASE)\n",
        "\n",
        "        for match in simple_matches:\n",
        "            extremity = match.group(1).lower()\n",
        "            if extremity in processed_extremities:\n",
        "                continue\n",
        "\n",
        "            strength = match.group(2)\n",
        "            if strength not in ['5', '5+']:\n",
        "                processed_extremities.add(extremity)\n",
        "                extremity_name = limb_map.get(extremity, extremity.upper())\n",
        "\n",
        "                severity = Severity.WARNING if int(strength.replace('+', '').replace('-', '')) <= 2 else Severity.MOTOR\n",
        "                confidence = 0.9\n",
        "\n",
        "                findings.append(ClinicalFinding(\n",
        "                    message=f\"Weakness in {extremity_name}: {strength}/5\",\n",
        "                    severity=severity,\n",
        "                    confidence=confidence,\n",
        "                    category=\"motor\"\n",
        "                ))\n",
        "\n",
        "        # === REFLEX ASSESSMENT ===\n",
        "        reflex_patterns = {\n",
        "            r'hoffmans?\\b|hoffman\\'?s?\\s+sign': (\n",
        "                \"Hoffman's signâ€”UMN risk\", Severity.WARNING, 0.85),\n",
        "            r'babinski\\b|babinski\\'?s?\\s+sign': (\n",
        "                \"Babinski reflex noted\", Severity.WARNING, 0.85),\n",
        "            r'(?:hyperreflexia|[\\d][\\+]?\\s+dtrs?|dtrs?\\s+[\\d][\\+]?)': (\n",
        "                \"Hyperreflexiaâ€”monitor for UMN lesion\", Severity.WARNING, 0.8),\n",
        "            r'(?:hyporeflexia|areflexia|0\\s+dtrs?|dtrs?\\s+0)': (\n",
        "                \"Hyporeflexiaâ€”possible LMN involvement\", Severity.WARNING, 0.8),\n",
        "            r'(?:normal\\s+reflexes|2\\+?\\s+dtrs?|dtrs?\\s+2\\+?)': (\n",
        "                \"Reflexes within normal limits\", Severity.NORMAL, 0.9)\n",
        "        }\n",
        "\n",
        "        for pattern, (message, severity, confidence) in reflex_patterns.items():\n",
        "            matches = re.finditer(pattern, exam_section, re.IGNORECASE)\n",
        "            for match in matches:\n",
        "                if not is_negated(match.group(0), blurb_lower):\n",
        "                    findings.append(ClinicalFinding(\n",
        "                        message=message,\n",
        "                        severity=severity,\n",
        "                        confidence=confidence,\n",
        "                        category=\"reflexes\"\n",
        "                    ))\n",
        "                    break\n",
        "\n",
        "        # === SENSORY ASSESSMENT ===\n",
        "        sensory_patterns = {\n",
        "            r'(?:decreased|diminished|reduced|impaired)\\s+sensation': (\n",
        "                \"Sensory deficit present\", Severity.NEURO, 0.8),\n",
        "            r'numbness\\b|paresthesia\\b|dysesthesia\\b': (\n",
        "                \"Sensory deficit present\", Severity.NEURO, 0.8),\n",
        "            r'sensation\\s+(?:is\\s+)?(?:intact|normal|preserved)|silt': (\n",
        "                \"Sensation intact\", Severity.NORMAL, 0.9)\n",
        "        }\n",
        "\n",
        "        for pattern, (message, severity, confidence) in sensory_patterns.items():\n",
        "            match = re.search(pattern, exam_section, re.IGNORECASE)\n",
        "            if match and not is_negated(match.group(0), blurb_lower):\n",
        "                if \"deficit\" in message and is_baseline_deficit_mentioned(blurb_lower):\n",
        "                    findings.append(ClinicalFinding(\n",
        "                        message=\"Sensory findings noted but consistent with baseline\",\n",
        "                        severity=Severity.NORMAL,\n",
        "                        confidence=0.7,\n",
        "                        category=\"sensory\"\n",
        "                    ))\n",
        "                else:\n",
        "                    findings.append(ClinicalFinding(\n",
        "                        message=message,\n",
        "                        severity=severity,\n",
        "                        confidence=confidence,\n",
        "                        category=\"sensory\"\n",
        "                    ))\n",
        "                break\n",
        "\n",
        "        # === CAUDA EQUINA ASSESSMENT ===\n",
        "        # Check for bowel/bladder dysfunction\n",
        "        bowel_bladder_pattern = r'(?:bowel|bladder)\\s+(?:incontinence|retention|dysfunction)'\n",
        "        bowel_bladder_match = re.search(bowel_bladder_pattern, blurb_lower, re.IGNORECASE)\n",
        "        if bowel_bladder_match and not is_negated(bowel_bladder_match.group(0), blurb_lower):\n",
        "            findings.append(ClinicalFinding(\n",
        "                message=\"Bowel/bladder dysfunctionâ€”evaluate for cauda equina\",\n",
        "                severity=Severity.WARNING,\n",
        "                confidence=0.9,\n",
        "                category=\"cauda_equina\"\n",
        "            ))\n",
        "\n",
        "        # Check for rectal tone\n",
        "        rectal_tone_pattern = r'\\+rectal\\s+tone|normal\\s+rectal\\s+tone|rectal\\s+tone\\s+(?:present|intact)'\n",
        "        rectal_tone_match = re.search(rectal_tone_pattern, exam_section, re.IGNORECASE)\n",
        "        if rectal_tone_match and not is_negated(rectal_tone_match.group(0), blurb_lower):\n",
        "            findings.append(ClinicalFinding(\n",
        "                message=\"Rectal tone intact\",\n",
        "                severity=Severity.NORMAL,\n",
        "                confidence=0.9,\n",
        "                category=\"cauda_equina\"\n",
        "            ))\n",
        "\n",
        "        return findings\n",
        "\n",
        "    except Exception as e:\n",
        "        clinical_logger.log_error(\n",
        "            component=\"extract_enhanced_exam_components\",\n",
        "            error_code=\"ENHANCED_EXAM_ERROR\",\n",
        "            error_message=str(e),\n",
        "            stack_trace=traceback.format_exc()\n",
        "        )\n",
        "        return []\n",
        "def risk_flag(blurb: str, prior_findings: Optional[ClinicalFindings] = None) -> ClinicalFindings:\n",
        "    \"\"\"\n",
        "    Enhanced universal risk flagging engine with structured output\n",
        "    \"\"\"\n",
        "    if not blurb:\n",
        "        return ClinicalFindings(\n",
        "            critical_flags=[ClinicalFinding(\n",
        "                message=\"Empty inputâ€”manual review advised\",\n",
        "                severity=Severity.WARNING,\n",
        "                confidence=0.0,\n",
        "                category=\"system\"\n",
        "            )]\n",
        "        )\n",
        "\n",
        "    start_time = time.time()\n",
        "    findings = ClinicalFindings()\n",
        "\n",
        "    try:\n",
        "        # Expand abbreviations\n",
        "        expanded_blurb, expanded_terms = expand_abbreviations(blurb, abbreviation_map)\n",
        "        blurb_lower = expanded_blurb.lower()\n",
        "\n",
        "        # === MOTOR STRENGTH ASSESSMENT ===\n",
        "        limb_map = {\n",
        "            \"rue\": \"RIGHT UPPER EXTREMITY\",\n",
        "            \"lue\": \"LEFT UPPER EXTREMITY\",\n",
        "            \"rle\": \"RIGHT LOWER EXTREMITY\",\n",
        "            \"lle\": \"LEFT LOWER EXTREMITY\",\n",
        "            \"right upper extremity\": \"RIGHT UPPER EXTREMITY\",\n",
        "            \"left upper extremity\": \"LEFT UPPER EXTREMITY\",\n",
        "            \"right lower extremity\": \"RIGHT LOWER EXTREMITY\",\n",
        "            \"left lower extremity\": \"LEFT LOWER EXTREMITY\",\n",
        "            \"right arm\": \"RIGHT UPPER EXTREMITY\",\n",
        "            \"left arm\": \"LEFT UPPER EXTREMITY\",\n",
        "            \"right leg\": \"RIGHT LOWER EXTREMITY\",\n",
        "            \"left leg\": \"LEFT LOWER EXTREMITY\"\n",
        "        }\n",
        "\n",
        "        # Detailed strength patterns (e.g., LLE 2/5/4+/4+/5 OR left lower extremity 2/5/4+/4+/5)\n",
        "        detailed_matches = patterns.detailed_strength_pattern.finditer(expanded_blurb)\n",
        "        for match in detailed_matches:\n",
        "            extremity = match.group(1).lower()\n",
        "            extremity_name = limb_map.get(extremity, extremity.upper())\n",
        "            strength_text = match.group(2)\n",
        "            values = re.findall(r'(\\d+[-+]?)', strength_text)\n",
        "\n",
        "            # Analyze the strength values - any value < 5 indicates weakness\n",
        "            weak_values = []\n",
        "            muscle_groups = [\"hip flexion\", \"knee extension\", \"ankle dorsiflexion\", \"EHL\", \"ankle plantarflexion\"]\n",
        "\n",
        "            for i, val in enumerate(values):\n",
        "                val_clean = val.strip().replace('+', '').replace('-', '')\n",
        "                if val_clean.isdigit() and int(val_clean) < 5:\n",
        "                    muscle_name = muscle_groups[i] if i < len(muscle_groups) else f\"muscle {i+1}\"\n",
        "                    weak_values.append(f\"{muscle_name}: {val}\")\n",
        "\n",
        "            if weak_values:\n",
        "                weakness_details = \", \".join(weak_values)\n",
        "                # Flag severe weakness (any muscle 2/5 or less) as WARNING instead of just MOTOR\n",
        "                has_severe_weakness = any(int(val.strip().replace('+', '').replace('-', '')) <= 2\n",
        "                                        for val in values if val.strip().replace('+', '').replace('-', '').isdigit())\n",
        "                severity = Severity.WARNING if has_severe_weakness else Severity.MOTOR\n",
        "                confidence = 0.95 if has_severe_weakness else 0.85\n",
        "\n",
        "                if severity == Severity.WARNING:\n",
        "                    findings.warning_flags.append(ClinicalFinding(\n",
        "                        message=f\"Significant weakness in {extremity_name}: {weakness_details}\",\n",
        "                        severity=severity,\n",
        "                        confidence=confidence,\n",
        "                        category=\"motor\"\n",
        "                    ))\n",
        "                else:\n",
        "                    findings.motor_flags.append(ClinicalFinding(\n",
        "                        message=f\"Weakness in {extremity_name}: {weakness_details}\",\n",
        "                        severity=severity,\n",
        "                        confidence=confidence,\n",
        "                        category=\"motor\"\n",
        "                    ))\n",
        "\n",
        "        # Generalized strength patterns (e.g., \"LLE 4+ throughout\")\n",
        "        generalized_matches = patterns.generalized_strength_pattern.finditer(expanded_blurb)\n",
        "        for match in generalized_matches:\n",
        "            extremity = match.group(1).lower()\n",
        "            extremity_name = limb_map.get(extremity, extremity.upper())\n",
        "            strength_value = match.group(2)\n",
        "\n",
        "            # Convert strength value to numeric for comparison\n",
        "            strength_numeric = strength_value.replace('+', '').replace('-', '')\n",
        "            if strength_numeric.isdigit() and int(strength_numeric) < 5:\n",
        "                severity = Severity.WARNING if int(strength_numeric) <= 3 else Severity.MOTOR\n",
        "                confidence = 0.9\n",
        "\n",
        "                if severity == Severity.WARNING:\n",
        "                    findings.warning_flags.append(ClinicalFinding(\n",
        "                        message=f\"Generalized weakness in {extremity_name}: {strength_value} throughout\",\n",
        "                        severity=severity,\n",
        "                        confidence=confidence,\n",
        "                        category=\"motor\"\n",
        "                    ))\n",
        "                else:\n",
        "                    findings.motor_flags.append(ClinicalFinding(\n",
        "                        message=f\"Weakness in {extremity_name}: {strength_value} throughout\",\n",
        "                        severity=severity,\n",
        "                        confidence=confidence,\n",
        "                        category=\"motor\"\n",
        "                    ))\n",
        "\n",
        "        # === DIRECT SENSORY LEVEL DETECTION ===\n",
        "        sensory_level_match = patterns.sensory_level_pattern.search(blurb_lower)\n",
        "        if sensory_level_match and not is_negated(sensory_level_match.group(0), blurb_lower):\n",
        "            level = sensory_level_match.group(1).upper()\n",
        "            findings.warning_flags.append(ClinicalFinding(\n",
        "                message=f\"Sensory level at {level}â€”possible cord involvement\",\n",
        "                severity=Severity.WARNING,\n",
        "                confidence=0.9,\n",
        "                category=\"sensory\"\n",
        "            ))\n",
        "\n",
        "        # === DIRECT CLONUS DETECTION ===\n",
        "        clonus_match = patterns.clonus_pattern.search(blurb_lower)\n",
        "        if clonus_match and not is_negated(clonus_match.group(0), blurb_lower):\n",
        "            side = clonus_match.group(1) if clonus_match.group(1) else \"\"\n",
        "            side_text = f\" {side}\" if side else \"\"\n",
        "            findings.warning_flags.append(ClinicalFinding(\n",
        "                message=f\"Clonus detected{side_text}â€”UMN involvement\",\n",
        "                severity=Severity.WARNING,\n",
        "                confidence=0.9,\n",
        "                category=\"reflexes\"\n",
        "            ))\n",
        "\n",
        "        # === BABINSKI DETECTION ===\n",
        "        babinski_match = patterns.babinski_pattern.search(blurb_lower)\n",
        "        if babinski_match and not is_negated(babinski_match.group(0), blurb_lower):\n",
        "            side = babinski_match.group(1) if babinski_match.group(1) else \"\"\n",
        "            side_text = f\" {side}\" if side else \"\"\n",
        "            findings.warning_flags.append(ClinicalFinding(\n",
        "                message=f\"Babinski sign{side_text}â€”UMN involvement\",\n",
        "                severity=Severity.WARNING,\n",
        "                confidence=0.9,\n",
        "                category=\"reflexes\"\n",
        "            ))\n",
        "\n",
        "        # === HYPERREFLEXIA DETECTION ===\n",
        "        hyperreflexia_match = patterns.hyperreflexia_pattern.search(blurb_lower)\n",
        "        if hyperreflexia_match and not is_negated(hyperreflexia_match.group(0), blurb_lower):\n",
        "            extremity = hyperreflexia_match.group(1) if hyperreflexia_match.group(1) else \"\"\n",
        "            reflex_grade = hyperreflexia_match.group(2)\n",
        "            extremity_text = f\" {extremity}\" if extremity else \"\"\n",
        "            findings.warning_flags.append(ClinicalFinding(\n",
        "                message=f\"Hyperreflexia{extremity_text} ({reflex_grade})â€”UMN involvement\",\n",
        "                severity=Severity.WARNING,\n",
        "                confidence=0.85,\n",
        "                category=\"reflexes\"\n",
        "            ))\n",
        "\n",
        "        # === SADDLE ANESTHESIA DETECTION ===\n",
        "        saddle_match = patterns.saddle_anesthesia_pattern.search(blurb_lower)\n",
        "        if saddle_match and not is_negated(saddle_match.group(0), blurb_lower):\n",
        "            findings.critical_flags.append(ClinicalFinding(\n",
        "                message=\"Saddle anesthesiaâ€”urgent cauda equina evaluation needed\",\n",
        "                severity=Severity.CRITICAL,\n",
        "                confidence=0.95,\n",
        "                category=\"cauda_equina\"\n",
        "            ))\n",
        "\n",
        "        # === SENSORY DEFICIT DETECTION ===\n",
        "        sensory_deficit_match = patterns.sensory_deficit_pattern.search(blurb_lower)\n",
        "        if sensory_deficit_match and not is_negated(sensory_deficit_match.group(0), blurb_lower):\n",
        "            # Check if it's bilateral\n",
        "            bilateral_match = patterns.bilateral_sensory_pattern.search(blurb_lower)\n",
        "            if bilateral_match:\n",
        "                findings.warning_flags.append(ClinicalFinding(\n",
        "                    message=\"Bilateral sensory deficitsâ€”possible cord/cauda equina involvement\",\n",
        "                    severity=Severity.WARNING,\n",
        "                    confidence=0.85,\n",
        "                    category=\"sensory\"\n",
        "                ))\n",
        "            else:\n",
        "                findings.neuro_flags.append(ClinicalFinding(\n",
        "                    message=\"Sensory deficit noted\",\n",
        "                    severity=Severity.NEURO,\n",
        "                    confidence=0.8,\n",
        "                    category=\"sensory\"\n",
        "                ))\n",
        "\n",
        "        # === REFLEX ABNORMALITIES ===\n",
        "        absent_reflexes_match = patterns.absent_reflexes_pattern.search(blurb_lower)\n",
        "        if absent_reflexes_match and not is_negated(absent_reflexes_match.group(0), blurb_lower):\n",
        "            findings.warning_flags.append(ClinicalFinding(\n",
        "                message=\"Absent reflexesâ€”possible lower motor neuron involvement\",\n",
        "                severity=Severity.WARNING,\n",
        "                confidence=0.9,\n",
        "                category=\"reflexes\"\n",
        "            ))\n",
        "\n",
        "        # === ENHANCED PHYSICAL EXAM ANALYSIS ===\n",
        "        exam_findings = extract_enhanced_exam_components(expanded_blurb, blurb_lower)\n",
        "        for finding in exam_findings:\n",
        "            if finding.severity == Severity.CRITICAL:\n",
        "                findings.critical_flags.append(finding)\n",
        "            elif finding.severity == Severity.WARNING:\n",
        "                findings.warning_flags.append(finding)\n",
        "            elif finding.severity == Severity.MOTOR:\n",
        "                findings.motor_flags.append(finding)\n",
        "            elif finding.severity == Severity.NEURO:\n",
        "                findings.neuro_flags.append(finding)\n",
        "            elif finding.severity == Severity.MONITORING:\n",
        "                findings.monitoring_flags.append(finding)\n",
        "            else:\n",
        "                findings.normal_findings.append(finding)\n",
        "\n",
        "        # === SPINAL TUBERCULOSIS CONTEXT ===\n",
        "        if re.search(r'potts\\s+disease|spinal\\s+tb|tuberculosis.*spine', blurb_lower):\n",
        "            findings.monitoring_flags.append(ClinicalFinding(\n",
        "                message=\"Known spinal TB/Potts diseaseâ€”monitor for neurological progression\",\n",
        "                severity=Severity.MONITORING,\n",
        "                confidence=0.9,\n",
        "                category=\"infection\"\n",
        "            ))\n",
        "\n",
        "        # === CALCULATE OVERALL CONFIDENCE ===\n",
        "        all_findings = findings.get_all_findings()\n",
        "        if all_findings:\n",
        "            findings.overall_confidence = sum(f.confidence for f in all_findings) / len(all_findings)\n",
        "        else:\n",
        "            findings.overall_confidence = 0.0\n",
        "\n",
        "        # === DEDUPLICATION ===\n",
        "        def deduplicate_findings(finding_list):\n",
        "            \"\"\"Remove duplicate findings based on clinical concepts\"\"\"\n",
        "            unique_findings = []\n",
        "            seen_concepts = set()\n",
        "\n",
        "            for finding in finding_list:\n",
        "                msg_lower = finding.message.lower()\n",
        "\n",
        "                # Define concept keys for similar findings\n",
        "                concept_key = None\n",
        "                if 'babinski' in msg_lower:\n",
        "                    concept_key = 'babinski'\n",
        "                elif 'clonus' in msg_lower:\n",
        "                    concept_key = 'clonus'\n",
        "                elif 'sensory level' in msg_lower:\n",
        "                    concept_key = 'sensory_level'\n",
        "                elif 'saddle anesthesia' in msg_lower:\n",
        "                    concept_key = 'saddle_anesthesia'\n",
        "                elif 'hoffman' in msg_lower:\n",
        "                    concept_key = 'hoffman'\n",
        "                elif 'hyperreflexia' in msg_lower:\n",
        "                    concept_key = 'hyperreflexia'\n",
        "                elif 'weakness' in msg_lower and 'right upper extremity' in msg_lower:\n",
        "                    concept_key = 'rue_weakness'\n",
        "                elif 'weakness' in msg_lower and 'left upper extremity' in msg_lower:\n",
        "                    concept_key = 'lue_weakness'\n",
        "                elif 'weakness' in msg_lower and 'right lower extremity' in msg_lower:\n",
        "                    concept_key = 'rle_weakness'\n",
        "                elif 'weakness' in msg_lower and 'left lower extremity' in msg_lower:\n",
        "                    concept_key = 'lle_weakness'\n",
        "                else:\n",
        "                    # For unique findings, use the full message\n",
        "                    concept_key = msg_lower.strip()\n",
        "\n",
        "                # Only add if we haven't seen this concept, or if this one is better\n",
        "                if concept_key not in seen_concepts:\n",
        "                    unique_findings.append(finding)\n",
        "                    seen_concepts.add(concept_key)\n",
        "                else:\n",
        "                    # If duplicate, keep the one with higher confidence or more specific message\n",
        "                    existing_idx = next(i for i, f in enumerate(unique_findings)\n",
        "                                      if concept_key == 'babinski' and 'babinski' in f.message.lower() or\n",
        "                                         concept_key == 'clonus' and 'clonus' in f.message.lower() or\n",
        "                                         concept_key == 'hyperreflexia' and 'hyperreflexia' in f.message.lower() or\n",
        "                                         concept_key in f.message.lower())\n",
        "\n",
        "                    if 0 <= existing_idx < len(unique_findings):\n",
        "                        existing_finding = unique_findings[existing_idx]\n",
        "                        # Keep the more specific (longer) or higher confidence finding\n",
        "                        if (finding.confidence > existing_finding.confidence or\n",
        "                            len(finding.message) > len(existing_finding.message)):\n",
        "                            unique_findings[existing_idx] = finding\n",
        "\n",
        "            return unique_findings\n",
        "\n",
        "        # Apply deduplication to all finding lists\n",
        "        findings.critical_flags = deduplicate_findings(findings.critical_flags)\n",
        "        findings.warning_flags = deduplicate_findings(findings.warning_flags)\n",
        "        findings.motor_flags = deduplicate_findings(findings.motor_flags)\n",
        "        findings.neuro_flags = deduplicate_findings(findings.neuro_flags)\n",
        "        findings.monitoring_flags = deduplicate_findings(findings.monitoring_flags)\n",
        "        findings.normal_findings = deduplicate_findings(findings.normal_findings)\n",
        "\n",
        "        # Recalculate confidence after deduplication\n",
        "        all_findings = findings.get_all_findings()\n",
        "        if all_findings:\n",
        "            findings.overall_confidence = sum(f.confidence for f in all_findings) / len(all_findings)\n",
        "        else:\n",
        "            findings.overall_confidence = 0.0\n",
        "\n",
        "        # Calculate processing time\n",
        "        findings.processing_time_ms = int((time.time() - start_time) * 1000)\n",
        "\n",
        "        # Log processing\n",
        "        clinical_logger.log_clinical_processing(blurb, findings, expanded_terms)\n",
        "\n",
        "        return findings\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error processing consult text: {str(e)}\"\n",
        "        clinical_logger.log_error(\n",
        "            component=\"risk_flag_engine\",\n",
        "            error_code=\"PROCESSING_ERROR\",\n",
        "            error_message=error_msg,\n",
        "            severity=\"high\",\n",
        "            stack_trace=traceback.format_exc()\n",
        "        )\n",
        "\n",
        "        return ClinicalFindings(\n",
        "            critical_flags=[ClinicalFinding(\n",
        "                message=f\"Error in processing: {error_msg}\",\n",
        "                severity=Severity.CRITICAL,\n",
        "                confidence=0.0,\n",
        "                category=\"system\"\n",
        "            )]\n",
        "        )\n",
        "\n",
        "# === OpenAI Integration ===\n",
        "def initialize_openai_client():\n",
        "    \"\"\"Initialize OpenAI client with error handling\"\"\"\n",
        "    try:\n",
        "        return OpenAI(api_key=config.openai_api_key)\n",
        "    except Exception as e:\n",
        "        clinical_logger.log_error(\n",
        "            component=\"openai_integration\",\n",
        "            error_code=\"CLIENT_INIT_ERROR\",\n",
        "            error_message=str(e),\n",
        "            severity=\"medium\"\n",
        "        )\n",
        "        return None\n",
        "\n",
        "# === GPT Summary Integration ===\n",
        "def gpt_summarize(consult: str) -> str:\n",
        "    \"\"\"Enhanced GPT summary with error handling\"\"\"\n",
        "    if not config.enable_gpt_summary:\n",
        "        return \"GPT summary disabled in configuration\"\n",
        "\n",
        "    client = initialize_openai_client()\n",
        "    if not client:\n",
        "        return \"GPT client initialization failed\"\n",
        "\n",
        "    try:\n",
        "        prompt = f\"\"\"\n",
        "You are a clinical AI engine trained to summarize neurological consults.\n",
        "\n",
        "Summarize the following consult note and its flagged neurological findings:\n",
        "\n",
        "Consult:\n",
        "{consult}\n",
        "\n",
        "Output a clear, 2â€“3 sentence summary with emphasis on the neuro exam and clinical concern.\n",
        "Focus on critical findings, motor/sensory deficits, and risk factors.\n",
        "\"\"\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a clinical summarizer for neurosurgical triage.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=200,\n",
        "            temperature=0.3\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        clinical_logger.log_error(\n",
        "            component=\"gpt_summary\",\n",
        "            error_code=\"SUMMARY_ERROR\",\n",
        "            error_message=str(e),\n",
        "            severity=\"low\"\n",
        "        )\n",
        "        return f\"GPT summary failed: {str(e)}\"\n",
        "\n",
        "# === Enhanced CLI Interface ===\n",
        "def format_findings_output(findings: ClinicalFindings) -> str:\n",
        "    \"\"\"Format clinical findings for display\"\"\"\n",
        "    output_lines = []\n",
        "\n",
        "    # Add critical findings first\n",
        "    if findings.critical_flags:\n",
        "        output_lines.append(\"ðŸš¨ CRITICAL FINDINGS:\")\n",
        "        for finding in findings.critical_flags:\n",
        "            output_lines.append(f\"  {finding.severity.value} {finding.message} (confidence: {finding.confidence:.2f})\")\n",
        "        output_lines.append(\"\")\n",
        "\n",
        "    # Warning findings\n",
        "    if findings.warning_flags:\n",
        "        output_lines.append(\"âš ï¸ WARNING FINDINGS:\")\n",
        "        for finding in findings.warning_flags:\n",
        "            output_lines.append(f\"  {finding.severity.value} {finding.message} (confidence: {finding.confidence:.2f})\")\n",
        "        output_lines.append(\"\")\n",
        "\n",
        "    # Motor findings\n",
        "    if findings.motor_flags:\n",
        "        output_lines.append(\"ðŸ¦´ MOTOR FINDINGS:\")\n",
        "        for finding in findings.motor_flags:\n",
        "            output_lines.append(f\"  {finding.severity.value} {finding.message} (confidence: {finding.confidence:.2f})\")\n",
        "        output_lines.append(\"\")\n",
        "\n",
        "    # Neuro findings\n",
        "    if findings.neuro_flags:\n",
        "        output_lines.append(\"ðŸ§  NEUROLOGICAL FINDINGS:\")\n",
        "        for finding in findings.neuro_flags:\n",
        "            output_lines.append(f\"  {finding.severity.value} {finding.message} (confidence: {finding.confidence:.2f})\")\n",
        "        output_lines.append(\"\")\n",
        "\n",
        "    # Monitoring findings\n",
        "    if findings.monitoring_flags:\n",
        "        output_lines.append(\"ðŸ” MONITORING:\")\n",
        "        for finding in findings.monitoring_flags:\n",
        "            output_lines.append(f\"  {finding.severity.value} {finding.message} (confidence: {finding.confidence:.2f})\")\n",
        "        output_lines.append(\"\")\n",
        "\n",
        "    # Normal findings\n",
        "    if findings.normal_findings:\n",
        "        output_lines.append(\"âœ… NORMAL FINDINGS:\")\n",
        "        for finding in findings.normal_findings:\n",
        "            output_lines.append(f\"  {finding.severity.value} {finding.message} (confidence: {finding.confidence:.2f})\")\n",
        "        output_lines.append(\"\")\n",
        "\n",
        "    # Summary statistics\n",
        "    total_findings = len(findings.get_all_findings())\n",
        "    output_lines.append(f\"ðŸ“Š SUMMARY: {total_findings} findings, overall confidence: {findings.overall_confidence:.2f}, processing time: {findings.processing_time_ms}ms\")\n",
        "\n",
        "    return \"\\n\".join(output_lines)\n",
        "\n",
        "# === Synapse Clinical Analysis Interface ===\n",
        "def run_synapse():\n",
        "    \"\"\"\n",
        "    Main Synapse interface - allows users to paste clinical text and get analysis\n",
        "    \"\"\"\n",
        "    print(\"ðŸ§  SYNAPSE v2.0 â€” Clinical Risk Flagging Engine\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Paste your clinical note below and press Enter to analyze:\")\n",
        "    print()\n",
        "\n",
        "    # Get clinical text from user\n",
        "    clinical_text = input(\"ðŸ“‹ Clinical Note: \")\n",
        "\n",
        "    if not clinical_text.strip():\n",
        "        print(\"âŒ No text provided. Please paste a clinical note.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nðŸ” Analyzing clinical findings...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        # Process the clinical text\n",
        "        findings = risk_flag(clinical_text)\n",
        "\n",
        "        # Display results\n",
        "        result = format_findings_output(findings)\n",
        "        print(result)\n",
        "\n",
        "        # Add GPT summary if enabled\n",
        "        if config.enable_gpt_summary:\n",
        "            print(\"\\nðŸ“‹ GPT CLINICAL SUMMARY:\")\n",
        "            print(\"-\" * 30)\n",
        "            summary = gpt_summarize(clinical_text)\n",
        "            print(summary)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"Analysis complete. Run again to analyze another case.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error during analysis: {str(e)}\")\n",
        "        print(\"Please check your input and try again.\")\n",
        "\n",
        "# === Auto-run Synapse ===\n",
        "def start_synapse():\n",
        "    \"\"\"\n",
        "    Auto-start Synapse interface\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        try:\n",
        "            run_synapse()\n",
        "\n",
        "            # Ask if user wants to analyze another case\n",
        "            print(\"\\nAnalyze another case? (y/n): \", end=\"\")\n",
        "            continue_analysis = input().lower().strip()\n",
        "\n",
        "            if continue_analysis not in ['y', 'yes']:\n",
        "                print(\"ðŸ‘‹ Exiting Synapse. Thank you!\")\n",
        "                break\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nðŸ‘‹ Exiting Synapse. Thank you!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Unexpected error: {str(e)}\")\n",
        "            break\n",
        "\n",
        "# === Entry Point ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Check if running in Jupyter/Colab\n",
        "    try:\n",
        "        __IPYTHON__\n",
        "        print(\"ðŸ§  Synapse v2.0 loaded successfully!\")\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"USAGE:\")\n",
        "        print(\"Just paste your clinical text below and press Enter:\")\n",
        "        print()\n",
        "\n",
        "        # Direct input in Jupyter\n",
        "        clinical_text = input(\"ðŸ“‹ Clinical Note: \")\n",
        "\n",
        "        if clinical_text.strip():\n",
        "            print(\"\\nðŸ” Analyzing clinical findings...\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "            findings = risk_flag(clinical_text)\n",
        "            result = format_findings_output(findings)\n",
        "            print(result)\n",
        "\n",
        "            if config.enable_gpt_summary:\n",
        "                print(\"\\nðŸ“‹ GPT CLINICAL SUMMARY:\")\n",
        "                print(\"-\" * 30)\n",
        "                summary = gpt_summarize(clinical_text)\n",
        "                print(summary)\n",
        "        else:\n",
        "            print(\"âŒ No text provided. Please run again and paste a clinical note.\")\n",
        "\n",
        "    except NameError:\n",
        "        # Command line mode\n",
        "        start_synapse()"
      ]
    }
  ]
}